{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2046.521240234375\n",
      "199 1439.64794921875\n",
      "299 1013.97216796875\n",
      "399 715.2403564453125\n",
      "499 505.4943542480469\n",
      "599 358.1595458984375\n",
      "699 254.620361328125\n",
      "799 181.8282012939453\n",
      "899 130.63232421875\n",
      "999 94.6123046875\n",
      "1099 69.26078796386719\n",
      "1199 51.41203308105469\n",
      "1299 38.841651916503906\n",
      "1399 29.986143112182617\n",
      "1499 23.74591636657715\n",
      "1599 19.347463607788086\n",
      "1699 16.246421813964844\n",
      "1799 14.059609413146973\n",
      "1899 12.517148971557617\n",
      "1999 11.428955078125\n",
      "Result: y = -0.05312396213412285 + 0.8473708033561707 x + 0.009164770133793354 x^2 + -0.09199760109186172 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math \n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "# 生成一些随机数据\n",
    "# X = torch.randn(10, 2)\n",
    "X = torch.tensor([[-0.2255,  0.4324],\n",
    "        [ 0.8043,  0.8567],\n",
    "        [-0.0747, -0.6191],\n",
    "        [-0.0945, -0.4330],\n",
    "        [-0.8426, -0.5141],\n",
    "        [-0.5853,  0.7330],\n",
    "        [-1.1090, -0.4401],\n",
    "        [-0.3951,  1.2259],\n",
    "        [ 0.0319,  0.9381],\n",
    "        [ 0.9036,  0.6088]])\n",
    "print(X,\"\\n\")\n",
    "# 计算距离矩阵\n",
    "dist_matrix = pdist(X)\n",
    "\n",
    "# 使用linkage函数计算链接矩阵\n",
    "Z = linkage(dist_matrix)\n",
    "\n",
    "# 使用dendrogram函数绘制树状图\n",
    "dendrogram(Z,above_threshold_color=\"#fff917\")\n",
    "\n",
    "t1=0.6\n",
    "t2=0.8\n",
    "t3=1\n",
    "# 假设Z是您之前计算出的链接矩阵\n",
    "# 假设t是您设定的距离阈值\n",
    "clusters1 = fcluster(Z, t1, criterion='distance')\n",
    "clusters2 = fcluster(Z, t2, criterion='distance')\n",
    "clusters3 = fcluster(Z, t3, criterion='distance')\n",
    "\n",
    "print(clusters1,\"\\n\")\n",
    "print(clusters2,\"\\n\")\n",
    "print(clusters3,\"\\n\")\n",
    "\n",
    "# clusters1 = np.array([5,1,2,4,3,6,1])\n",
    "clusters1 = np.array([1,1,1,1,2,2,2])\n",
    "print(\"\\nclusters1:\\n\",clusters1)\n",
    "cluster_indices = []\n",
    "for x in range(np.max(clusters1)):\n",
    "    print(\"\\n@@@\\n\",np.where(clusters1==(x+1))[0])\n",
    "    cluster_indices.append(np.where(clusters1==(x+1))[0])\n",
    "print(\"\\ncluster idcs:\\n\",cluster_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FedAvg': 3}\n"
     ]
    }
   ],
   "source": [
    "accs  = [0.7494830254628592, 0.7218213661006894, 0.7498688440238601, 0.7262314659070352, 0.7251887130394649, 0.7273124530464166, 0.7252269473112758, 0.730724267253467, 0.7248411287502747]\n",
    "ratios = {}\n",
    "\n",
    "clients_over_avg = len([acc for acc  in accs if acc > 0.73])\n",
    "ratios[\"FedAvg\"] = clients_over_avg\n",
    "\n",
    "print(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device', type=str, default='gpu',\n",
    "                        help='CPU / GPU device.')\n",
    "    parser.add_argument('--num_repeat', type=int, default=5,\n",
    "                        help='number of repeating rounds to simulate;')\n",
    "    parser.add_argument('--num_rounds', type=int, default=50,\n",
    "                        help='number of rounds to simulate;')\n",
    "    \n",
    "    parser.add_argument('--comm_threshold', type=int, default=10,\n",
    "                        help='the communication round threshold to cluster;')\n",
    "    parser.add_argument('--dist_threshold',type=float,default=1.0,\n",
    "                        help='the distance threshold to cluster')\n",
    "    \n",
    "    parser.add_argument('--local_epoch', type=int, default=1,\n",
    "                        help='number of local epochs;')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='learning rate for inner solver;')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                        help='Weight decay (L2 loss on parameters).')\n",
    "    parser.add_argument('--nlayer', type=int, default=3,\n",
    "                        help='Number of GINconv layers')\n",
    "    parser.add_argument('--hidden', type=int, default=64,\n",
    "                        help='Number of hidden units.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                        help='Dropout rate (1 - keep probability).')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='Batch size for node classification.')\n",
    "    parser.add_argument('--seed', help='seed for randomness;',\n",
    "                        type=int, default=123)\n",
    "\n",
    "    parser.add_argument('--datapath', type=str, default='./data',\n",
    "                        help='The input path of data.')\n",
    "    parser.add_argument('--outbase', type=str, default='./outputs',\n",
    "                        help='The base path for outputting.')\n",
    "    parser.add_argument('--repeat', help='index of repeating;',\n",
    "                        type=int, default=None)\n",
    "    parser.add_argument('--data_group', help='specify the group of datasets',\n",
    "                        type=str, default='mix')\n",
    "\n",
    "    parser.add_argument('--convert_x', help='whether to convert original node features to one-hot degree features',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--overlap', help='whether clients have overlapped data',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--standardize', help='whether to standardize the distance matrix',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--seq_length', help='the length of the gradient norm sequence',\n",
    "                        type=int, default=10)\n",
    "    parser.add_argument('--epsilon1', help='the threshold epsilon1 for GCFL',\n",
    "                        type=float, default=0.01)\n",
    "    parser.add_argument('--epsilon2', help='the threshold epsilon2 for GCFL',\n",
    "                        type=float, default=0.1)\n",
    "\n",
    "    try:\n",
    "        args = parser.parse_args()\n",
    "    except IOError as msg:\n",
    "        parser.error(str(msg))\n",
    "\n",
    "    seed_dataSplit = 123\n",
    "\n",
    "    # set seeds\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    # torch.cuda.manual_seed(args.seed)\n",
    "    # torch.backends.mps.manual_seed(args.seed)\n",
    "    \n",
    "    args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # args.device = torch.device(\"mps\")\n",
    "    # args.device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    EPS_1 = args.epsilon1\n",
    "    EPS_2 = args.epsilon2\n",
    "\n",
    "    # TODO: change the data input path and output path\n",
    "    outbase = os.path.join(args.outbase, f'seqLen{args.seq_length}')\n",
    "\n",
    "    if args.overlap and args.standardize:\n",
    "        outpath = os.path.join(outbase, f\"standardizedDTW/multiDS-overlap\")\n",
    "    elif args.overlap:\n",
    "        outpath = os.path.join(outbase, f\"multiDS-overlap\")\n",
    "    elif args.standardize:\n",
    "        outpath = os.path.join(outbase, f\"standardizedDTW/multiDS-nonOverlap\")\n",
    "    else:\n",
    "        outpath = os.path.join(outbase, f\"multiDS-nonOverlap\")\n",
    "    outpath = os.path.join(outpath, args.data_group, f'eps_{EPS_1}_{EPS_2}')\n",
    "    Path(outpath).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output Path: {outpath}\")\n",
    "\n",
    "    # preparing data\n",
    "    if not args.convert_x:\n",
    "        \"\"\" using original features \"\"\"\n",
    "        suffix = \"\"\n",
    "        print(\"Preparing data (original features) ...\")\n",
    "    else:\n",
    "        \"\"\" using node degree features \"\"\"\n",
    "        suffix = \"_degrs\"\n",
    "        print(\"Preparing data (one-hot degree features) ...\")\n",
    "\n",
    "    if args.repeat is not None:\n",
    "        Path(os.path.join(outpath, 'repeats')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    splitedData, df_stats = setupGC.prepareData_multiDS(args.datapath, args.data_group, args.batch_size, convert_x=args.convert_x, seed=seed_dataSplit)\n",
    "    print(\"Done\")\n",
    "\n",
    "    # save statistics of data on clients\n",
    "    if args.repeat is None:\n",
    "        outf = os.path.join(outpath, f'stats_trainData{suffix}.csv')\n",
    "    else:\n",
    "        outf = os.path.join(outpath, \"repeats\", f'{args.repeat}_stats_trainData{suffix}.csv')\n",
    "    df_stats.to_csv(outf)\n",
    "    print(f\"Wrote to {outf}\")\n",
    "\n",
    "    init_clients, init_server, init_idx_clients = setupGC.setup_devices(splitedData, args)\n",
    "    print(\"\\nDone setting up devices.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
