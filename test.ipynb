{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import sys\n",
    "import setupGC\n",
    "from training import *\n",
    "from numpy import mean\n",
    "import torch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "mean_accs_fedavg = []\n",
    "mean_accs_fedprox = []\n",
    "mean_accs_ghcfl = []\n",
    "mean_accs_gcfl = []\n",
    "clients_over_ghcfl = []\n",
    "dw_ghcfl = []\n",
    "ratios = {}\n",
    "last_acc_fedavg = []\n",
    "last_acc_fedprox = []\n",
    "last_acc_gcfl = []\n",
    "last_acc_ghcfl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fedavg(clients, server, COMMUNICATION_ROUNDS, local_epoch, samp=None, frac=1.0):\n",
    "    for client in clients:\n",
    "        client.download_from_server(server)\n",
    "\n",
    "    if samp is None:\n",
    "        sampling_fn = server.randomSample_clients\n",
    "        frac = 1.0\n",
    "    \n",
    "    for c_round in range(1, COMMUNICATION_ROUNDS + 1):\n",
    "        if (c_round) % 50 == 0:\n",
    "            print(f\"  > round {c_round}\")\n",
    "\n",
    "        if c_round == 1:\n",
    "            selected_clients = clients\n",
    "        else:\n",
    "            selected_clients = sampling_fn(clients, frac)\n",
    "\n",
    "        for client in selected_clients:\n",
    "            # only get weights of graphconv layers\n",
    "            client.local_train(local_epoch)\n",
    "\n",
    "        server.aggregate_weights(selected_clients)\n",
    "        for client in selected_clients:\n",
    "            client.download_from_server(server)\n",
    "        accs = []   \n",
    "        for client in clients:\n",
    "            loss, acc = client.evaluate()\n",
    "            accs.append(acc)\n",
    "        mean_accs_fedavg.append(mean(accs))\n",
    "        if c_round == COMMUNICATION_ROUNDS:\n",
    "            print(\"final accs:\",accs) \n",
    "            last_acc_fedavg = accs\n",
    "            \n",
    "    clients_over_avg = len([acc for acc  in accs if acc > 0.75])\n",
    "    ratios[\"FedAvg\"] = clients_over_avg\n",
    "    \n",
    "    # plt.plot(mean_accs)\n",
    "     \n",
    "    frame = pd.DataFrame()\n",
    "    for client in clients:\n",
    "        loss, acc = client.evaluate()\n",
    "        frame.loc[client.name, 'test_acc'] = acc\n",
    "\n",
    "    def highlight_max(s):\n",
    "        is_max = s == s.max()\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "    fs = frame.style.apply(highlight_max).data\n",
    "    print(fs)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fedprox(clients, server, COMMUNICATION_ROUNDS, local_epoch, mu, samp=None, frac=1.0):\n",
    "    for client in clients:\n",
    "        client.download_from_server(server)\n",
    "\n",
    "    if samp is None:\n",
    "        sampling_fn = server.randomSample_clients\n",
    "        frac = 1.0\n",
    "    if samp == 'random':\n",
    "        sampling_fn = server.randomSample_clients\n",
    "\n",
    "    for c_round in range(1, COMMUNICATION_ROUNDS + 1):\n",
    "        if (c_round) % 50 == 0:\n",
    "            print(f\"  > round {c_round}\")\n",
    "\n",
    "        if c_round == 1:\n",
    "            selected_clients = clients\n",
    "        else:\n",
    "            selected_clients = sampling_fn(clients, frac)\n",
    "\n",
    "        for client in selected_clients:\n",
    "            client.local_train_prox(local_epoch, mu)\n",
    "\n",
    "        server.aggregate_weights(selected_clients)\n",
    "        for client in selected_clients:\n",
    "            client.download_from_server(server)\n",
    "\n",
    "            # cache the aggregated weights for next round\n",
    "            client.cache_weights()\n",
    "        accs = []   \n",
    "        for client in clients:\n",
    "            loss, acc = client.evaluate()\n",
    "            accs.append(acc)\n",
    "        mean_accs_fedprox.append(mean(accs))\n",
    "        if c_round == COMMUNICATION_ROUNDS:\n",
    "            print(\"final accs:\",accs) \n",
    "            last_acc_fedprox = accs\n",
    "   \n",
    "    clients_over_prox = len([acc for acc  in accs if acc > 0.85])\n",
    "    ratios[\"FedProx\"] = clients_over_prox\n",
    "    \n",
    "    frame = pd.DataFrame()\n",
    "    for client in clients:\n",
    "        loss, acc = client.evaluate()\n",
    "        frame.loc[client.name, 'test_acc'] = acc\n",
    "\n",
    "    def highlight_max(s):\n",
    "        is_max = s == s.max()\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "    fs = frame.style.apply(highlight_max).data\n",
    "    print(fs)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gcfl(clients, server, COMMUNICATION_ROUNDS, local_epoch, EPS_1, EPS_2):\n",
    "    cluster_indices = [np.arange(len(clients)).astype(\"int\")]\n",
    "    client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "    # print(\"\\nidcs:\\n\")\n",
    "    # for idcs in cluster_indices:\n",
    "    #     for i in idcs:\n",
    "    #         print(\"\\n\",clients[i])\n",
    "    # print(\"cluster_indices[0]:\\n\",cluster_indices[0])\n",
    "    # print(\"cluster_indices:\\n\",cluster_indices,\"\\n\")\n",
    "    # print(\"client_clusters:\\n\",client_clusters,\"\\n\")\n",
    "    print(\"running GCFL...\")\n",
    "    \n",
    "    for c_round in range(1, COMMUNICATION_ROUNDS + 1):\n",
    "        if (c_round) % 50 == 0:\n",
    "            print(f\"  > round {c_round}\")\n",
    "        if c_round == 1:\n",
    "            for client in clients:\n",
    "                client.download_from_server(server)\n",
    "\n",
    "        participating_clients = server.randomSample_clients(clients, frac=1.0)\n",
    "\n",
    "        for client in participating_clients:\n",
    "            client.compute_weight_update(local_epoch)\n",
    "            client.reset()\n",
    "\n",
    "        similarities = server.compute_pairwise_similarities(clients)\n",
    "    \n",
    "        cluster_indices_new = []\n",
    "        for idc in cluster_indices:\n",
    "            max_norm = server.compute_max_update_norm([clients[i] for i in idc])\n",
    "            mean_norm = server.compute_mean_update_norm([clients[i] for i in idc])\n",
    "            if mean_norm < EPS_1 and max_norm > EPS_2 and len(idc) > 2 and c_round > 20:\n",
    "                server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "                # print(\"\\nbi-partition occurs at round \",c_round,\"\\n\")\n",
    "                # print(\"\\nidc:\",idc)\n",
    "                # print(\"\\nsimilarities:\",similarities[idc][:, idc])\n",
    "                # print(\"\\nsimilarities[idc][:, idc]:\",similarities[idc][:, idc])\n",
    "                c1, c2 = server.min_cut(similarities[idc][:, idc], idc)\n",
    "                cluster_indices_new += [c1, c2]\n",
    "                # print(\"\\nc1:\",c1,\"\\nc2:\",c2)\n",
    "                # print(\"\\ncluster_indices_new\",cluster_indices_new)\n",
    "            else:\n",
    "                cluster_indices_new += [idc]\n",
    "\n",
    "        cluster_indices = cluster_indices_new\n",
    "        \n",
    "        client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]  # initial: [[0, 1, ...]]\n",
    "\n",
    "        server.aggregate_clusterwise(client_clusters)\n",
    "\n",
    "        acc_clients = [client.evaluate()[1] for client in clients]\n",
    "        accs = []   \n",
    "        for client in clients:\n",
    "            loss, acc = client.evaluate()\n",
    "            accs.append(acc)\n",
    "        mean_accs_gcfl.append(mean(accs))\n",
    "        if c_round == COMMUNICATION_ROUNDS:\n",
    "            print(\"final accs:\",accs) \n",
    "            last_acc_gcfl = accs\n",
    "        \n",
    "    clients_over_gcfl = len([acc for acc  in accs if acc > 0.85])\n",
    "    ratios[\"GCFL\"] = clients_over_gcfl\n",
    "    for idc in cluster_indices:\n",
    "        server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "\n",
    "    results = np.zeros([len(clients), len(server.model_cache)])\n",
    "    for i, (idcs, W, accs) in enumerate(server.model_cache):\n",
    "        results[idcs, i] = np.array(accs)\n",
    "\n",
    "    frame = pd.DataFrame(results, columns=[\"FL Model\"] + [\"Model {}\".format(i)\n",
    "                                                          for i in range(results.shape[1] - 1)],\n",
    "                         index=[\"{}\".format(clients[i].name) for i in range(results.shape[0])])\n",
    "    frame = pd.DataFrame(frame.max(axis=1))\n",
    "    frame.columns = ['test_acc']\n",
    "    print(frame)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device', type=str, default='gpu',\n",
    "                        help='CPU / GPU device.')\n",
    "    parser.add_argument('--num_repeat', type=int, default=5,\n",
    "                        help='number of repeating rounds to simulate;')\n",
    "    parser.add_argument('--num_rounds', type=int, default=50,\n",
    "                        help='number of rounds to simulate;')\n",
    "    \n",
    "    parser.add_argument('--comm_threshold', type=int, default=10,\n",
    "                        help='the communication round threshold to cluster;')\n",
    "    parser.add_argument('--dist_threshold',type=float,default=1.0,\n",
    "                        help='the distance threshold to cluster')\n",
    "    \n",
    "    parser.add_argument('--local_epoch', type=int, default=1,\n",
    "                        help='number of local epochs;')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='learning rate for inner solver;')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                        help='Weight decay (L2 loss on parameters).')\n",
    "    parser.add_argument('--nlayer', type=int, default=3,\n",
    "                        help='Number of GINconv layers')\n",
    "    parser.add_argument('--hidden', type=int, default=64,\n",
    "                        help='Number of hidden units.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                        help='Dropout rate (1 - keep probability).')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='Batch size for node classification.')\n",
    "    parser.add_argument('--seed', help='seed for randomness;',\n",
    "                        type=int, default=123)\n",
    "\n",
    "    parser.add_argument('--datapath', type=str, default='./data',\n",
    "                        help='The input path of data.')\n",
    "    parser.add_argument('--outbase', type=str, default='./outputs',\n",
    "                        help='The base path for outputting.')\n",
    "    parser.add_argument('--repeat', help='index of repeating;',\n",
    "                        type=int, default=None)\n",
    "    parser.add_argument('--data_group', help='specify the group of datasets',\n",
    "                        type=str, default='mix')\n",
    "\n",
    "    parser.add_argument('--convert_x', help='whether to convert original node features to one-hot degree features',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--overlap', help='whether clients have overlapped data',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--standardize', help='whether to standardize the distance matrix',\n",
    "                        type=bool, default=False)\n",
    "    parser.add_argument('--seq_length', help='the length of the gradient norm sequence',\n",
    "                        type=int, default=10)\n",
    "    parser.add_argument('--epsilon1', help='the threshold epsilon1 for GCFL',\n",
    "                        type=float, default=0.01)\n",
    "    parser.add_argument('--epsilon2', help='the threshold epsilon2 for GCFL',\n",
    "                        type=float, default=0.1)\n",
    "\n",
    "    try:\n",
    "        args = parser.parse_args(\"\")\n",
    "    except IOError as msg:\n",
    "        parser.error(str(msg))\n",
    "\n",
    "    seed_dataSplit = 123\n",
    "\n",
    "    # set seeds\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    # torch.cuda.manual_seed(args.seed)\n",
    "    # torch.backends.mps.manual_seed(args.seed)\n",
    "    \n",
    "    args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # args.device = torch.device(\"mps\")\n",
    "    # args.device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    EPS_1 = args.epsilon1\n",
    "    EPS_2 = args.epsilon2\n",
    "\n",
    "    # TODO: change the data input path and output path\n",
    "    outbase = os.path.join(args.outbase, f'seqLen{args.seq_length}')\n",
    "\n",
    "    if args.overlap and args.standardize:\n",
    "        outpath = os.path.join(outbase, f\"standardizedDTW/multiDS-overlap\")\n",
    "    elif args.overlap:\n",
    "        outpath = os.path.join(outbase, f\"multiDS-overlap\")\n",
    "    elif args.standardize:\n",
    "        outpath = os.path.join(outbase, f\"standardizedDTW/multiDS-nonOverlap\")\n",
    "    else:\n",
    "        outpath = os.path.join(outbase, f\"multiDS-nonOverlap\")\n",
    "    outpath = os.path.join(outpath, args.data_group, f'eps_{EPS_1}_{EPS_2}')\n",
    "    Path(outpath).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output Path: {outpath}\")\n",
    "\n",
    "    # preparing data\n",
    "    if not args.convert_x:\n",
    "        \"\"\" using original features \"\"\"\n",
    "        suffix = \"\"\n",
    "        print(\"Preparing data (original features) ...\")\n",
    "    else:\n",
    "        \"\"\" using node degree features \"\"\"\n",
    "        suffix = \"_degrs\"\n",
    "        print(\"Preparing data (one-hot degree features) ...\")\n",
    "\n",
    "    if args.repeat is not None:\n",
    "        Path(os.path.join(outpath, 'repeats')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    splitedData, df_stats = setupGC.prepareData_multiDS(args.datapath, args.data_group, args.batch_size, convert_x=args.convert_x, seed=seed_dataSplit)\n",
    "    print(\"Done\")\n",
    "\n",
    "    # save statistics of data on clients\n",
    "    if args.repeat is None:\n",
    "        outf = os.path.join(outpath, f'stats_trainData{suffix}.csv')\n",
    "    else:\n",
    "        outf = os.path.join(outpath, \"repeats\", f'{args.repeat}_stats_trainData{suffix}.csv')\n",
    "    df_stats.to_csv(outf)\n",
    "    print(f\"Wrote to {outf}\")\n",
    "\n",
    "    init_clients, init_server, init_idx_clients = setupGC.setup_devices(splitedData, args)\n",
    "    print(\"\\nDone setting up devices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ghcfl(clients, server, comm_threshold, dist_threshold, COMMUNICATION_ROUNDS, local_epoch, frac=1.0):\n",
    "    print(\"running hierarchical clustering...\")\n",
    "    \n",
    "    '''initialize w_0'''\n",
    "    for client in clients:\n",
    "        client.download_from_server(server)#initialize all the clients \n",
    "    '''for round 1 - n, do fedAvg selecting a partial clients'''\n",
    "    for c_round in range(1,comm_threshold):#1-n round communication, do FEDERATED_LEARNING\n",
    "        if (c_round) % 50 == 0:\n",
    "            print(f\"  > round {c_round}\")\n",
    "        if c_round == 1:\n",
    "            selected_clients = clients\n",
    "        else:\n",
    "            selected_clients = server.randomSample_clients(clients, frac)\n",
    "            \n",
    "        for client in selected_clients:\n",
    "            client.compute_weight_update(local_epoch) #client_update\n",
    "        \n",
    "        server.aggregate_weights(selected_clients) #W(t+1) = sum(n{k}/n * W(t))\n",
    "        \n",
    "        #pass the aggregated weights from server to selected clients:\n",
    "        for client in selected_clients:\n",
    "            client.download_from_server(server)#到了这一步，客户端最后存储了server进行Avg操作后的joint global model\n",
    "            # cache the aggregated weights for next round\n",
    "            client.cache_weights()#这里已经把joint global model的w存到了w_old\n",
    "        \n",
    "        accs = []\n",
    "        client_dWs = []         \n",
    "        for client in clients:\n",
    "            loss, acc = client.evaluate()\n",
    "            accs.append(acc)\n",
    "            dW = []\n",
    "            for k in client.W.keys():\n",
    "                dW.append(client.dW[k])\n",
    "            client_dWs.append(dW)\n",
    "        mean_accs_ghcfl.append(np.mean(accs))#每一个round计算一次所有clients的mean_acc\n",
    "        # dw_ghcfl.append(np.mean(client_dWs))\n",
    "        clients_over_ghcfl.append(len([acc for acc  in accs if acc > 0.75]))\n",
    "    # print(\"\\nmean_accs:\",mean_accs_ghcfl)\n",
    "    \n",
    "    \n",
    "    '''for each of all clients, do CLIENT_UPDATE to get delta W'''\n",
    "    for client in clients:\n",
    "        client.compute_weight_update(local_epoch)\n",
    "    '''server cluster the clients by hierarchical_clustering_algorithm'''\n",
    "    client_clusters = server.hierarchical_clustering_clients(clients, dist_threshold)\n",
    "    \n",
    "    \n",
    "    '''for the rest of the communication rounds, update by clusters'''\n",
    "    for client in clients:\n",
    "        client.download_from_server(server)#initialize all the clients \n",
    "    for c_round in range(comm_threshold,COMMUNICATION_ROUNDS + 1):\n",
    "        if (c_round) % 50 == 0:\n",
    "            print(f\"  > round {c_round}\")\n",
    "        selected_clients = server.randomSample_clients(clients, frac)\n",
    "        \n",
    "        for client in selected_clients:\n",
    "            client.compute_weight_update(3) #client_update\n",
    "            \n",
    "        server.aggregate_clusterwise(client_clusters)#aggregate by clusters\n",
    "        #pass the aggregated weights from server to selected clients:\n",
    "        for client in selected_clients:\n",
    "            client.download_from_server(server)#到了这一步，客户端最后存储了server进行Avg操作后的joint global model\n",
    "            # cache the aggregated weights for next round\n",
    "            client.cache_weights()#这里已经把joint global model的w存到了w_old\n",
    "            \n",
    "        accs = [] \n",
    "        client_dWs = []    \n",
    "        for client in clients:\n",
    "            loss, acc = client.evaluate()\n",
    "            accs.append(acc)\n",
    "            dW = []\n",
    "            for k in client.W.keys():\n",
    "                dW.append(client.dW[k])\n",
    "            client_dWs.append(dW)\n",
    "        mean_accs_ghcfl.append(np.mean(accs))#每一个round计算一次所有clients的mean_acc\n",
    "        # dw_ghcfl.append(np.mean(client_dWs))\n",
    "        # if c_round == COMMUNICATION_ROUNDS:\n",
    "        #     print(\"final accs:\",accs) \n",
    "        #     last_acc_ghcfl = accs\n",
    "            \n",
    "        clients_over_ghcfl.append(len([acc for acc  in accs if acc > 0.75]))\n",
    "    # last_acc_ghcfl = accs \n",
    "    \n",
    "    ratios[\"HCFL\"] = clients_over_ghcfl\n",
    "    print(\"\\nmean_accs:\",mean_accs_ghcfl)\n",
    "   \n",
    "   \n",
    "    '''test and output results to file'''\n",
    "    frame = pd.DataFrame()\n",
    "    for client in clients:\n",
    "        loss, acc = client.evaluate()\n",
    "        frame.loc[client.name, 'test_acc'] = acc\n",
    "\n",
    "    print(frame)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_clients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m9\u001b[39m):\n\u001b[1;32m     32\u001b[0m     sys\u001b[39m.\u001b[39margv \u001b[39m=\u001b[39m commands[i]\n\u001b[0;32m---> 34\u001b[0m     clients\u001b[39m=\u001b[39mcopy\u001b[39m.\u001b[39mdeepcopy(init_clients)\n\u001b[1;32m     35\u001b[0m     server\u001b[39m=\u001b[39mcopy\u001b[39m.\u001b[39mdeepcopy(init_server)\n\u001b[1;32m     36\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_clients' is not defined"
     ]
    }
   ],
   "source": [
    "commands = [[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"molecules\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"1\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"biochem\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"1\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"mix\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"1\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"molecules\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"3\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"biochem\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"3\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"mix\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"3\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"molecules\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"5\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"biochem\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"5\"\n",
    "],[\"main_multiDS.py\",\"--repeat\",\"1\", \"--data_group\", \"mix\", \"--seed\",\n",
    "            \"10\",\"--epsilon1\", \"0.07\", \"--epsilon2\", \"0.28\",\"--seq_length\",\"5\",\"--num_rounds\",\"50\",\n",
    "            \"--comm_threshold\",\"5\"\n",
    "]]\n",
    "\n",
    "df = pd.DataFrame\n",
    "for i in range (9):\n",
    "    sys.argv = commands[i]\n",
    "\n",
    "    clients=copy.deepcopy(init_clients)\n",
    "    server=copy.deepcopy(init_server)\n",
    "    fig, ax = plt.subplots()\n",
    "    # run_fedavg(clients, server, args.num_rounds, args.local_epoch, samp=None)\n",
    "    # run_fedprox(clients, server, args.num_rounds, args.local_epoch, mu = 0.01, samp=None)\n",
    "    # run_gcfl(clients, server, args.num_rounds, args.local_epoch, EPS_1, EPS_2)\n",
    "    run_ghcfl(clients, server, args.comm_threshold, args.dist_threshold, args.num_rounds, args.local_epoch)\n",
    "    # run_ghcfl_new(clients, server, args.comm_threshold, args.dist_threshold, args.num_rounds, args.local_epoch)\n",
    "    clients=copy.deepcopy(init_clients)\n",
    "    server=copy.deepcopy(init_server)\n",
    "    run_fedavg(clients, server, args.num_rounds, args.local_epoch, samp=None)\n",
    "    # clients=copy.deepcopy(init_clients)\n",
    "    # server=copy.deepcopy(init_server)\n",
    "    # run_fedprox(clients, server, args.num_rounds, args.local_epoch, mu = 0.01, samp=None)\n",
    "    ax.plot(mean_accs_ghcfl, label='GHCFL')\n",
    "    ax.plot(mean_accs_fedavg, label='FedAvg')\n",
    "    # ax.plot(mean_accs_fedprox,label = 'FedProx')\n",
    "    # ax.plot(mean_accs_gcfl,label = \"GCFL\")\n",
    "    plt.axvline(args.comm_threshold-1)\n",
    "    # plt.ylim((0.2, 1.4))\n",
    "    plt.xticks(np.arange(len(mean_accs_ghcfl)), np.arange(1, len(mean_accs_ghcfl)+1))\n",
    "    plt.xticks(np.arange(len(mean_accs_fedavg)), np.arange(1, len(mean_accs_fedavg)+1))\n",
    "    ax.legend() #自动检测要在图例中显示的元素，并且显示\n",
    "    \n",
    "    name = commands[i][4]\n",
    "    r = commands[i][14]\n",
    "    n = commands[i][16]\n",
    "    \n",
    "    figure_save_path = \"file_figs\"\n",
    "    if not os.path.exists(figure_save_path):\n",
    "        os.makedirs(figure_save_path) # 如果不存在目录figure_save_path，则创建\n",
    "    plt.savefig(os.path.join(figure_save_path , '{r}r_{n}n_{name},.png'))\n",
    "    plt.show() #图形可视化\n",
    "        \n",
    "    mean_acc_fedavg = np.mean(mean_accs_fedavg)\n",
    "    mean_acc_fedprox = np.mean(mean_accs_fedprox)\n",
    "    mean_acc_gcfl = np.mean(mean_accs_gcfl)\n",
    "    mean_acc_ghcfl = np.mean(mean_accs_ghcfl)\n",
    "    \n",
    "    ds = f'{r}r_{n}n_{name}'\n",
    "    df.loc[ds, \"accuracy\"] = mean_acc_ghcfl/mean_acc_fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_acc_fedavg)\n",
    "print(mean_acc_fedprox)\n",
    "print(mean_acc_gcfl)\n",
    "print(mean_acc_ghcfl)\n",
    "print(mean_acc_ghcfl/mean_acc_fedavg)\n",
    "\n",
    "print(ratios)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(last_acc_fedavg)\n",
    "print(last_acc_fedprox)\n",
    "print(last_acc_gcfl)\n",
    "print(last_acc_ghcfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "fig, ax2 = plt.subplots()\n",
    "ax1.plot(mean_accs_ghcfl, label='GHCFL')\n",
    "ax1.plot(mean_accs_fedavg, label='FedAvg')\n",
    "ax1.plot(mean_accs_fedprox,label = 'FedProx')\n",
    "ax1.plot(mean_accs_gcfl,label = \"GCFL\")\n",
    "ax2.plot(clients_over_ghcfl, label = \"GHCFL\")\n",
    "plt.axvline(args.comm_threshold-1)\n",
    "# plt.ylim((0.2, 1.4))\n",
    "plt.xticks(np.arange(len(mean_accs_ghcfl)), np.arange(1, len(mean_accs_ghcfl)+1))\n",
    "plt.xticks(np.arange(len(mean_accs_fedavg)), np.arange(1, len(mean_accs_fedavg)+1))\n",
    "ax1.legend() #自动检测要在图例中显示的元素，并且显示\n",
    "ax2.legend()\n",
    "plt.show() #图形可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
